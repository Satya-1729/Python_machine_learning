{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJRurkjOGnXrz9IU6DAoVo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satya-1729/Python_machine_learning/blob/main/creation_of_sequential_and_dense_function_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this code is wrong cause the concept here uses is opposite of what i learnt\n",
        "#that is i added three neurons predicted value to form one value to the like in this code i did it\n",
        "#in this eg after matrix multiplication each neuron has it predicted value like for neuron1 in layer 1 the predicted values are at column1 or 0 whatever\n",
        "#for first row for of inputs from training example gives the value after multiplication by the weights of neuron1 like wise for second row in the\n",
        "#x_train gives the second value like this upto all training examples this process goes for all three neurons and for all the rows or samples in the x_train\n",
        "#now what i did is i added neuron1 first value and neuron2 first value and neuron 3 first value or in simple way row wise addition and makes it to nx1 matrix\n",
        "#why i did this because i thought the value that second layer will take is of three inputs in the array that makes the big blunder out of it\n",
        "\n",
        "# chatgpt explanation\n",
        "'''What Went Wrong in Your Code\n",
        "What You Did:\n",
        "\n",
        "After computing the matrix multiplication for the layer, you summed up the outputs row-wise:\n",
        "For example:\n",
        "If the output matrix was\n",
        "(\n",
        "5\n",
        ",\n",
        "3\n",
        ")\n",
        "(5,3):\n",
        "You added the outputs of all neurons for the first training example (row 1) and collapsed the row to a single value.\n",
        "Repeated this for all rows, resulting in an output of shape\n",
        "(\n",
        "5\n",
        ",\n",
        "1\n",
        ")\n",
        "(5,1).\n",
        "This essentially combined the outputs of all neurons into one value for each training example, which is not correct.\n",
        "Why It's Wrong:\n",
        "\n",
        "The second layer expects the outputs of all neurons individually as its inputs.\n",
        "By summing the outputs row-wise, you lost the individual contributions of each neuron, which breaks the fundamental principle of a neural network layer.'''\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the dataset as a NumPy array\n",
        "shirt_data = np.array([\n",
        "    [\"Shirt_ID\", \"Brand\", \"Material\", \"Price\", \"Durability_Rating\", \"Style\", \"Comfort_Rating\",\n",
        "     \"Sales_Last_Year\", \"Return_Rate\", \"Production_Cost\", \"Environmental_Impact\", \"Customer_Feedback\",\n",
        "     \"Reliability_Score\", \"Popularity\", \"Market_Trend\"],\n",
        "\n",
        "    [1, \"Zara\", \"Cotton\", 25, 8, \"Casual\", 9, 15000, \"3%\", 12, \"Medium\", 4.5, 8.5, \"High\", \"Increasing\"],\n",
        "    [2, \"H&M\", \"Polyester\", 20, 6, \"Formal\", 7, 12000, \"5%\", 8, \"High\", 4.0, 6.7, \"Medium\", \"Stable\"],\n",
        "    [3, \"Nike\", \"Dri-Fit\", 30, 9, \"Sports\", 8, 18000, \"2%\", 15, \"Low\", 4.7, 8.9, \"High\", \"Increasing\"],\n",
        "    [4, \"Uniqlo\", \"Linen\", 35, 7, \"Casual\", 8, 14000, \"4%\", 18, \"Medium\", 4.3, 7.5, \"Medium\", \"Stable\"],\n",
        "    [5, \"Leviâ€™s\", \"Cotton\", 40, 9, \"Formal\", 9, 16000, \"3%\", 20, \"Low\", 4.8, 8.9, \"High\", \"Increasing\"]\n",
        "])\n",
        "\n",
        "shirt_data\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(shirt_data)\n",
        "df\n",
        "\n",
        "df1 = df.copy()\n",
        "x_train = df1.iloc[1:,[3,4,6,9]].to_numpy()\n",
        "x_train = x_train.astype(float)\n",
        "print(x_train)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train = df1.iloc[1:,-1]\n",
        "\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_train\n",
        "\n",
        "#\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "def my_dense(a,w,b):\n",
        "  a = np.matmul(a,w)\n",
        "  a = np.sum(a, axis=1)\n",
        "  a = a.reshape(a.shape[0],1)\n",
        "  a = a+b\n",
        "  a = sigmoid(a)\n",
        "  return a\n",
        "\n",
        "def my_sequential(x,w1,b1,w2,b2):\n",
        "  a1 = my_dense(x,w1,b1)\n",
        "  a2 = my_dense(a1,w2,b2)\n",
        "  return a2\n",
        "\n",
        "w1 = np.random.rand(4,3)\n",
        "print(w1,\"\\n\\n\\n\\n\")\n",
        "b1 = np.random.rand(5,1)\n",
        "print(b1,\"\\n\\n\\n\\n\")\n",
        "w2 = np.random.rand(1,3)\n",
        "print(w2,\"\\n\\n\\n\\n\")\n",
        "b2 = np.random.rand(1,1)\n",
        "print(b2,\"\\n\\n\\n\\n\")\n",
        "y_pred = my_sequential(x_train,w1,b1,w2,b2)\n",
        "y_pred\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QjkHC7njWh1",
        "outputId": "0dc6f28f-4c52-4c7c-9909-ea0e4b4f9e80"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[25.  8.  9. 12.]\n",
            " [20.  6.  7.  8.]\n",
            " [30.  9.  8. 15.]\n",
            " [35.  7.  8. 18.]\n",
            " [40.  9.  9. 20.]]\n",
            "[[0.88811541 0.34968901 0.67976594]\n",
            " [0.46127365 0.29261855 0.24515167]\n",
            " [0.57091182 0.92472325 0.082982  ]\n",
            " [0.39794451 0.67926705 0.67238815]] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[[0.10417354]\n",
            " [0.63210958]\n",
            " [0.40377216]\n",
            " [0.89029007]\n",
            " [0.61292779]] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[[0.24129134 0.53709172 0.31140181]] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[[0.43754138]] \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.82161478],\n",
              "       [0.82161478],\n",
              "       [0.82161478],\n",
              "       [0.82161478],\n",
              "       [0.82161478]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.zeros((4,)).dtype"
      ],
      "metadata": {
        "id": "dwH8vTXXfPX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea52139f-2581-4c00-eeec-bc702af2aeaa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_dense(a, w, b):\n",
        "    # Matrix multiplication to compute weighted sums\n",
        "    z = np.dot(a, w)  # Shape: (n_samples, units)\n",
        "\n",
        "    # Broadcast and add bias\n",
        "    z += b  # Bias should have shape (units,) or broadcastable\n",
        "\n",
        "    return z  # Return the weighted sum (pre-activation)\n",
        "\n",
        "# Random inputs and weights\n",
        "w1 = np.random.rand(4, 3)  # Weights: 4 inputs, 3 neurons\n",
        "print(\"Weights:\\n\", w1, \"\\n\")\n",
        "\n",
        "b1 = np.random.rand(3)  # Bias: 3 neurons\n",
        "print(\"Bias:\\n\", b1, \"\\n\")\n",
        "\n",
        "x_train = np.random.rand(5, 4)  # 5 samples, 4 features\n",
        "print(\"Input:\\n\", x_train, \"\\n\")\n",
        "\n",
        "# Compute dense layer output\n",
        "dense_value = my_dense(x_train, w1, b1)\n",
        "print(\"Dense Layer Output:\\n\", dense_value)\n"
      ],
      "metadata": {
        "id": "Mxtkozu0k_ZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00597100-d5f9-4ffd-9e07-fb22edd393a5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights:\n",
            " [[0.899373   0.33267789 0.99279434]\n",
            " [0.39285777 0.74028372 0.46405679]\n",
            " [0.91653184 0.54037698 0.43087828]\n",
            " [0.38095423 0.11699874 0.77923087]] \n",
            "\n",
            "Bias:\n",
            " [0.51593429 0.95391422 0.86364126] \n",
            "\n",
            "Input:\n",
            " [[0.1557841  0.05920808 0.03842804 0.87706577]\n",
            " [0.16444693 0.81680223 0.53091259 0.49623418]\n",
            " [0.62351317 0.52727375 0.76590795 0.4425832 ]\n",
            " [0.2214645  0.55041459 0.98608775 0.85331703]\n",
            " [0.23987353 0.51801839 0.36294233 0.0932416 ]] \n",
            "\n",
            "Dense Layer Output:\n",
            " [[1.04864508 1.17295214 1.74577328]\n",
            " [1.66036132 1.95823919 2.02138557]\n",
            " [2.15443175 2.01733615 2.40223417]\n",
            " [2.16020368 2.06774966 2.42874836]\n",
            " [1.30334659 1.62423025 1.571217  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# correct version of code\n",
        "#im just getting the concept wrong here the array of b i m adding row wise instead of\n",
        "#adding column wise\n",
        "\n",
        "print(x_train , \"\\n\\n\\n\")\n",
        "print(y_train ,\"\\n\\n\\n\")\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "def my_dense(a,w,b):\n",
        "  a = np.matmul(a,w)\n",
        "\n",
        "  a = a+ b\n",
        "  print(a,\"\\n\\n\\n\\n\")\n",
        "\n",
        "  a = sigmoid(a)\n",
        "  return a\n",
        "\n",
        "def my_sequential(x,w1,b1,w2,b2):\n",
        "  a1 = my_dense(x,w1,b1)\n",
        "  a2 = my_dense(a1,w2,b2)\n",
        "  return a2\n",
        "\n",
        "# the mistake that i was doing that adding the bias row wise instead of column wise\n",
        "# and it leads to dimension error\n",
        "w1 = np.random.rand(4,3)\n",
        "# here shape of w suggests that there are 4features corresponding to them we have four weights\n",
        "# and 3 is the column number inside the weight array this suggest number of neurons in the layer\n",
        "\n",
        "print(w1,\"\\n\\n\\n\\n\")\n",
        "b1 = np.random.rand(3)\n",
        "# here bias has shape of 3 it means there are 3 neurons in the layer\n",
        "\n",
        "print(b1,\"\\n\\n\\n\\n\")\n",
        "w2 = np.random.rand(3,1)\n",
        "print(w2,\"\\n\\n\\n\\n\")\n",
        "b2 = np.random.rand(1)\n",
        "print(b2,\"\\n\\n\\n\\n\")\n",
        "y_pred = my_sequential(x_train,w1,b1,w2,b2)\n",
        "print(y_pred)\n",
        "\n",
        "b = np.zeros(5)\n",
        "print(b)\n",
        "\n",
        "for q in range (y_pred.shape[0]):\n",
        "  if y_pred[q] > 0.5:\n",
        "    b[q] = 1\n",
        "  else:\n",
        "    b[q] = 0\n",
        "\n",
        "print(b)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c6pHIn8ndx6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d893ab2-8672-4e2b-bb44-dc005e40fe04"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.1557841  0.05920808 0.03842804 0.87706577]\n",
            " [0.16444693 0.81680223 0.53091259 0.49623418]\n",
            " [0.62351317 0.52727375 0.76590795 0.4425832 ]\n",
            " [0.2214645  0.55041459 0.98608775 0.85331703]\n",
            " [0.23987353 0.51801839 0.36294233 0.0932416 ]] \n",
            "\n",
            "\n",
            "\n",
            "[0 1 0 1 0] \n",
            "\n",
            "\n",
            "\n",
            "[[0.154607   0.91699484 0.27053482]\n",
            " [0.2886422  0.21614697 0.92331988]\n",
            " [0.66726999 0.27473236 0.8561663 ]\n",
            " [0.27715429 0.77308432 0.26405668]] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[0.29609013 0.51689262 0.21768219] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[[0.14023845]\n",
            " [0.00047044]\n",
            " [0.40604121]] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[0.06508022] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[[0.60598981 1.36114669 0.57899107]\n",
            " [1.04907384 1.37372867 1.60192396]\n",
            " [1.17841432 1.75519343 1.64581818]\n",
            " [1.38369021 1.7695411  1.85538394]\n",
            " [0.75072106 1.02061913 1.09623307]] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[[0.41639802]\n",
            " [0.50725866]\n",
            " [0.51311093]\n",
            " [0.52874182]\n",
            " [0.46504469]] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[[0.60262101]\n",
            " [0.62416362]\n",
            " [0.62553547]\n",
            " [0.62918961]\n",
            " [0.61421023]]\n",
            "[0. 0. 0. 0. 0.]\n",
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KnTO2Td87D-a"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}